#!/bin/bash
#SBATCH --nodes 1
#SBATCH --ntasks 1
#SBATCH --cpus-per-task 1
#SBATCH --mem 128G
#SBATCH --partition gpu
#SBATCH --gres gpu:1
#SBATCH --qos gpu
#SBATCH --time 24:00:00

#SBATCH --mail-user=thibault.golaz@epfl.ch 
#SBATCH --mail-type=ALL

srun ./distributed_train.sh 1 --dataset torch/CIFAR10 \
  --data-dir ./data/CIFAR10/ \
  --model MONet_T_no_multistage \
  --opt adamw \
  --lr 1e-4 \
  --batch-size 64 \
  --epochs 300 \
  --sched cosine \
  --warmup-epochs 10 \
  --min-lr 1e-5 \
  --warmup-lr 1e-5 \
  --lr-base 1e-3 \
  --smoothing 0.1 \
  --mixup 0.5 \
  --cutmix 0.5 \
  --weight-decay 0.01 \
  --experiment Upd_Exp2_CIFAR10_no_multi \
  --num-classes 10 \
  --img-size 32 \
  --resume ./output/train/Upd_Exp1_CIFAR10/model_best.pth.tar